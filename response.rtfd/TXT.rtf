{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Arial-BoldMT;\f1\froman\fcharset0 Times-Bold;\f2\fswiss\fcharset0 ArialMT;
\f3\froman\fcharset0 Times-Roman;\f4\fswiss\fcharset0 Arial-ItalicMT;}
{\colortbl;\red255\green255\blue255;\red27\green31\blue34;\red255\green255\blue255;\red0\green0\blue0;
\red16\green60\blue192;\red10\green77\blue204;}
{\*\expandedcolortbl;;\cssrgb\c14118\c16078\c18039;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;
\cssrgb\c6667\c33333\c80000;\cssrgb\c1176\c40000\c83922;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid102\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
\margl1440\margr1440\vieww28600\viewh16580\viewkind0
\deftab720
\pard\pardeftab720\sl920\sa320\qc\partightenfactor0

\f0\b\fs61\fsmilli30667 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Granular Image Processing Pipeline Interview Challenge
\f1\fs48 \cf4 \strokec4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\b0\fs29\fsmilli14667 \cf4 \cb1 It was pleasure to work on the assignment. Project is not complete, may I need little more time. The github link to this project is {\field{\*\fldinst{HYPERLINK "https://github.com/channagithub/image_processing_pipeline"}}{\fldrslt \cf5 \ul \ulc5 \strokec5 https://github.com/channagithub/image_processing_pipeline}}. My architecture is as shown in the repo (unable to include image in this file - tried to, but failed for sometime). 
\f3\fs24 \
\pard\pardeftab720\sl400\qc\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 
\f3\fs24 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 * Farmers upload images using POST flask endpoint.
\f3\fs24 \

\f2\fs29\fsmilli14667 * It will be pushed to Kafka.
\f3\fs24 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 \outl0\strokewidth0 * 
\fs29\fsmilli14667 \cf4 \outl0\strokewidth0 \strokec4 Kafka publishes the image.
\f3\fs24 \

\f2\fs29\fsmilli14667 \cf4 \outl0\strokewidth0 * 
\fs29\fsmilli14667 \cf4 \outl0\strokewidth0 \strokec4 Subscribers (spark here) get the image and process. I have planned for 2 workers because getting geo location is pretty faster compared to image augmentation, so image augmentation should not be bottleneck for geolocation (if real time is not needed, we can put both of them in one single module, which would be more efficient in terms of memory.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 Worker 1 pushes the augmented images to S3, and these images can be pulled by any machine learning model(CNN here) in streaming or in batch fashion. Geo-location can be put to no-sql or sql. In the architecture above, I have put elasticsearch, but later I was thinking as we do not need heavy indexing for this particular use case, we can just do good with RDBMS. If scaling is an issue we can choose newer databases which are easy to scale, like may be coackroad DB.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\
\pard\pardeftab720\sl400\partightenfactor0

\f0\b\fs29\fsmilli14667 \cf4 Implementation
\f3\b0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 I have put all the components into containers. I have used docker to containerize the application. I\'92m not able to get the whole flow in one shot as of now. May be I was slow or time was less.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 Reasons to choose containerization is to have forward compatibility, scalability, robustness, easy shipping of code to production in mind. This will also get the possibility of Infrastructure as code into picture later in the stages of development.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 If I see, I haven\'92t met any of the coding tasks, as achieving them would be trivial without having these things in mind. But the code for all the things in the tasks (image augmentation, location of the images) is included.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 When it comes to serving prediction to the client, we can use the flask endpoint, which has preloaded model (or can be loaded periodically after training over certain period). My another project in my git repo has this thing implemented.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 I feel terrible for not actually getting the job done. I only request more time. Saying that, this repo has a lot of scope in the process of further development meeting all the objectives of the project (without having spend time cleaning or refactoring). I believe I have followed all the industry standards in building data pipeline (I frequently read blogs on data engineering)
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs29\fsmilli14667 \cf4 Finally, thank you for going through. I hope to talk to you soon.
\f3\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f0\b\fs29\fsmilli14667 \cf4 Things that work (independently)
\f3\b0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf4 \
\pard\pardeftab720\sl400\partightenfactor0

\f4\i\fs29\fsmilli14667 \cf4 REST endpoint
\f3\i0\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls1\ilvl0
\f2\fs29\fsmilli14667 \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Install docker on your machine\uc0\u8232 \
\pard\pardeftab720\fi960\sl400\partightenfactor0
\cf4 (Have 4 GB allocated for less surprises - I have 4GB set on my personal Mac)
\f3\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls2\ilvl0
\f2\fs29\fsmilli14667 \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Clone the repo.\uc0\u8232 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Run ./deploy.sh\uc0\u8232 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sl400\partightenfactor0
\ls2\ilvl1\cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 You will have flask app running, you can test it 
\fs32 \cf2 \cb3 \strokec2 curl {\field{\*\fldinst{HYPERLINK "http://0.0.0.0:8000/is_alive"}}{\fldrslt \cf6 \ul \ulc6 \strokec6 http://0.0.0.0:8000/is_alive}}
\fs29\fsmilli14667 \cf4 \cb1 \strokec4 \uc0\u8232 \
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 You can upload image 
\fs32 \cf2 \cb3 \strokec2 curl -F "file=@imgs_de/alfalfa/17254133335_e3c5643574_z.jpg" {\field{\*\fldinst{HYPERLINK "http://0.0.0.0:8000/post_image"}}{\fldrslt \cf6 \ul \ulc6 \strokec6 http://0.0.0.0:8000/post_image}}
\fs29\fsmilli14667 \cf4 \cb1 \strokec4 \uc0\u8232 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls2\ilvl0\cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 There are 2 workers as of now, but we can increase to multiple workers in needed.\uc0\u8232 \
\pard\pardeftab720\sl400\partightenfactor0

\f4\i \cf4 Kafka Queue (and zookeeper)
\f3\i0\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls3\ilvl0
\f2\fs29\fsmilli14667 \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 $ 
\f4\i pipenv shell 
\f2\i0 (this will create virtual env, make sure you install pipenv first)\uc0\u8232 \
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 $ 
\f4\i pip install -r requirements.txt
\f2\i0 \uc0\u8232 \
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 In python-client folder of the repo, run 
\f4\i python producer, 
\f2\i0 In another shell, same repo, save env, run 
\f4\i python consumer. 
\f2\i0 Both communicate, indicating kafka and zookeeper working in sync.\uc0\u8232 \
\pard\pardeftab720\sl400\partightenfactor0

\f4\i \cf4 Note: I have also include MySql container. Thinking I would push geo-location for POC. But I did not yet hit that stage.
\f3\i0\fs24 \
}